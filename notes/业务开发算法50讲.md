---
tags: [geek-time]
title: 业务开发算法50讲
created: '2024-02-20T14:55:24.715Z'
modified: '2024-02-20T14:56:49.482Z'
---

## 开篇词｜真实世界的算法，和你想的不一样

需要对算法、数据结构、操作系统、程序是如何运行的、内存是如何分配的等知识都有比较清晰的认识才行。毕竟，真实世界的算法，远不是时间复杂度这么简单。

真实世界的算法、工程中的算法。我希望能真正帮助遇到类似问题的你，我们不只会讨论基础的数据结构和算法思想，更会着重掌握这些算法是如何运行在真实的物理机器上的，如何解决实际业务系统中的问题，还有具体是如何在各个稳定运行的中间件、分布式系统、基础库中实现的。

## 先导篇｜诶，这个 git diff 好像不是很直观？

像 git diff 这样求解两段文本差异的问题，我们一般称为“文本差分”问题。

一系列插入和删除操作的序列就被称作编辑脚本

文本差分问题成功转化成了，如何在这样的网格中找到仅允许向下和向右移动的一个从 (0,0) 出发到 (m,n) 的路径，路径的长度就代表了总共需要的操作数

## 01｜动态数组：按需分配的vector为什么要二倍扩容？

基于下标随机访问数组元素为什么这么高效？动态数组是怎么做到看起来可以有无限容量？扩容机制的时间复杂度是多少，是不是会带来额外的内存浪费呢？

因为数组元素的类型都是一样的，所以每个元素占用的空间大小也是一样的，这样我们就很容易用“数组的开始地址 +index* 元素大小”的计算方式，快速定位到指定索引位置的元素，这也是数组基于下标随机访问的复杂度为 O(1) 的原因。

在长度为 N 的数组中，要在下标为 T 的位置插入数据时，原数组中下标为 T 到 N-1 的元素都需要向后顺移一位

为什么扩容是采用倍增的方式，而不是每次扩展固定大小？这背后其实是有严密数学依据的

每次扩容都会进行所有元素的复制

因为数组元素的类型都是一样的，所以每个元素占用的空间大小也是一样的，这样我们就很容易用“数组的开始地址 +index* 元素大小”的计算方式，快速定位到指定索引位置的元素，这也是数组基于下标随机访问的复杂度为 O(1) 的原因。

## 02｜双向链表：list如何实现高效地插入与删除？

有没有办法让我们不再需要连续的存储空间去存储一个序列，同时又可以在序列中快速进行插入 / 删除操作而不用波及之后的所有元素呢？

有没有办法让我们不再需要连续的存储空间去存储一个序列，同时又可以在序列中快速进行插入 / 删除操作而不用波及之后的所有元素呢？

因为有了指针来关联节点的地址，就不需要连续存储了。

链表

数组要求事先分配内存，而链表是每次插入新节点的时候，才申请该节点所需的内存空间，灵活得多，也就不会有分配空间没有被使用的浪费问题，自然内存使用率高。

正是因为这样非连续的存储方式，我们需要访问链表中第 n 个元素的时候就不得不从头节点遍历

链表更适用于删除、插入、遍历操作频繁的场景，而不适用于随机访问索引频繁的场景

链表的最大优势之一就是它的插入和删除效率会高效得多。这正是因为内存空间不是线性排列的，所以想要插入数据，我们只需要修改指定位置的前、后指针的指向，把新的节点在逻辑上插入某个位置就可以了

链表，相比于数组，有更好的灵活性和更低的插入、删除的复杂度，更加适用于查询索引较少、遍历、插入、删除操作较多的场景，所以要频繁在容器中间某个位置插入元素的时候，就经常用到，比如在 LRU 和操作系统进程调度的场景下就都会用到。

## 03｜双端队列：并行计算中的工作窃取算法如何实现？

所有的插入操作必须在队列的尾部进行，而所有的删除操作则必须在队列的头部进行

双端队列是两端开口的，在队列的头尾两端都可以进行进队和出队操作，让我们在使用队列时有了更大的灵活性。

数组也可以在两边插入数据呀，那双端队列和数组有什么区别呢？ 首先，数组头部的插入操作复杂度很高，如果我们并不需要快速随机访问，这种操作的复杂度是完全可以避免的，这是双端队列和数组的一个很大区别。更本质的地方在于，双端队列仅仅是一个两端都支持 FIFO 插入删除操作的队列，语义上来说并不支持数组基于下标在指定位置的修改、插入和删除的操作。

deque 的内存布局，可以说同时具备了 list 和 vector 的特点。

deque 的内存布局是由一段段连续的空间、用另一个类似数组的东西将这些空间的地址信息拼接在一起组成的，真实存放数据的就是那一段段连续的空间。在首尾两端插入和删除的时间复杂度是 O(1)。以插入为例，每次一段连续的空间元素被用完的时候，会直接申请一段新的空间并链接到 deque 的分段空间末尾。 所以 deque 既不像 vector 那样每次扩容都需要付出复制和拷贝的高昂代价，也不会像链表那样每次插入一个新的节点都需要申请一次内存。

deque 底层实质是分段连续空间

迭代器既要能找到与当前缓冲区相邻的缓冲区在哪；也需要知道目前访问的地方是否已经到当前缓冲区的边缘，只有这样到边缘时，才能正确跳转

这让我们将内存实质不连续的真相隐藏了起来

相比于 vector 和 list 来说，deque 支持的操作要少得多，只有基本的 push 和 pop 实现，因为队列语义保证了我们不会在队列中间进行插入删除操作，也就不用支持 insert 和 erase 这样的操作了。

为什么说工作窃取算法需要用到双端队列了吗？ 我们一起看看。为了更公平也更高效地分配每个进程负责的任务，我们可能会多开很多个队列去存储任务，每个进程就去消费一个队列中的任务，这样就可以有效避免进程间的竞争。因为任务先进先出，用一个普通的单向队列就可以完成了。 但是你可能很难保证任务划分得非常均匀，使得每个进程完成所有任务的时间都差不多。这不是一个很好解决的问题。但是如果我们换一个思路，不再费心让任务分配得均匀，只是简单地允许先完成任务的进程，去其他进程的队列盗取任务，是不是就不会有进程闲置了呢？ 不过怎么盗取，可以让我们仍然尽量规避进程间的竞争问题呢？ 相信你已经想到答案了，没错，就是双端队列。我们让盗取任务的进程，从队列的另一端盗取就行了，这样只有队列长度为 1 的时候才会出现竞争。

我们来回答一下为什么 C++ 不选择依赖已有的序列式容器来实现 deque？ 其实我们已有的容器就两个，一个是 vector，另外一种就是 list。 显然，基于 vector 实现，不能真的在头部插入元素，会产生 O(N) 的时间开销，我们只能用一个固定大小的 vector 来模拟循环队列，具体实现方式前面说过。但这样就导致我们必须事先确定数组的最大容量，让它的大小是实现分配好的，这就和数组一样，也会产生内存浪费和无法动态扩容的问题。 不过在最大容量能确定的场景下，用 vector 也是一种非常常见的循环队列实现方式。 而基于 list，看起来首尾都可以 O(1) 的时间插入，但对数据的随机读取性能会很差；且每次插入元素都需要申请内存，相比于 deque 一次申请一段内存的方式也会带来额外的性能开销。而 list 的最大优势，任意位置的快速插入 / 删除能力，我们却用不上。 所以基于 deque 的使用场景，C++ 设计了基于 map 分段存储的双端队列的数据结构，能同时具备 list 和 vector 的特点。

## 04｜栈：函数调用的秘密究竟是什么？

vector、deque 和 list，也对应着数组、队列和链表

栈区是有结构和固定大小的，区块按照次序存放，每个线程独占一个栈区，总的大小也是事先确定的；而堆区则没有固定的大小，数据可以随意存放。我们常常听到的 stack overflow 错误，也就是栈溢出错误，就是指程序在运行时，存放在栈上的数据已经多于栈区的容量，产生了容量不足的错误

stack 有单侧开口、后进先出的特性

除了可以利用其他数据结构，stack 实现起来非常简单还有另一个原因，它不需要暴露迭代器。在标准的栈“后进先出”的语义下，我们并不需要对 stack 做随机访问和遍历的操作

每个函数都有一个自己的作用域，但不同作用域下的变量可以有相同的变量名。比如在刚才的例子中，avg 和 add 函数中的入参变量名都是 a 和 b，它们互相不影响。这就是因为每个函数都会有一个自己的上下文，而上下文中存放着变量名和值的绑定，不同的上下文是彼此隔离的。 当程序每次执行到一个函数调用的时候，操作系统或者虚拟机就会在栈上分配一块区域，我们称之为栈帧。 简单来说，栈帧中就存放着函数执行的上下文。当前计算完成之后，我们就会将执行结果返回，并绑定到上一个栈帧内的变量里，当前栈帧的所有资源也就可以释放了。 这个释放过程，在操作系统或者虚拟机底层，最后都会转化成几个寄存器值的变化，成本非常低廉。

## 05｜HashMap：一个优秀的散列表是怎么来的？

序列式容器，数组、链表、队列、栈；今天来谈一谈另一类容器，关联式容器。所谓“关联式”，就是存储数据的时候，不只是存储元素的值本身，同时对要存储的元素关联一个键，形成一组键值对。这样在访问的时候，我们就可以基于键，访问到容器内的元素。

如何能把单词对应到一个数字，并且可以不同的单词有不同的编号，且每个单词都可以通过计算或者查找等手段对应到一个唯一的编号上？

这里的本质问题是什么呢？这个问题，其实可以抽象成一个给字符串动态编码的问题，为了让我们不需要遍历整个符号表来完成指定键的查找操作，我们需要找到一个更高效的给字符串编码的方式。

散列函数的本质，就是将一个更大且可能不连续空间（比如所有的单词），映射到一个空间有限的数组里，从而借用数组基于下标 O(1) 快速随机访问数组元素的能力。

## 06｜TreeMap：红黑树真的有那么难吗？

相比于 HashMap，基于红黑树的 TreeMap 的一个显著特点就是其维护的键值对是有序排列的。

每次比较总可以排除左右子树中的一颗

O(h) 在大部分时候是一个比 O(n) 小得多的数

如果要实现具备良好查找特性的 OrderedMap，我们需要同时保证树的有序性和平衡性，这里平衡性指的是，树上每个节点的左右子树的高度差要尽量小，最好不要超过一。

红黑树本质上是对“2-3 树”的一种实现。

这样的操作可以保证整个 2-3 Tree 是一个真正意义上的平衡树

这样的操作可以保证整个 2-3 Tree 是一个真正意义上的平衡树。但是，因为它的实现引入了两种异构的节点，导致代码写起来相当复杂，并没有被广泛使用。 而红黑树，正是采用标准的二叉查找树节点附着上额外的颜色信息来表示 2-3 树的实现，每一个红色节点都和它的父亲节点一起，构成了一个 3 节点的模拟，这就是红黑树设计的本质。

红黑树的查询、插入、删除的时间复杂度都非常良好且稳定，广泛运用于各种中间件里，还是非常值得掌握的。

当然红黑树是一个比较复杂的数据结构，如果直接从定义和几条绕口令一样的约束入手，很不好学。不过只要掌握它的本质，其实很简单。只要搞清楚，红黑树本质是 2-3 树在二叉树上的一种模拟，通过旋转操作完成 2-3 节点的合并和分裂，从而在不改变二叉树节点结构的前提下，保证二叉树的有序性和平衡性。

什么时候我们该用 TreeMap 什么时候该用 HashMap 呢？

## 07｜堆：如何实现一个高效的优先队列？

一种有趣的树，heap，也就是堆

我们常说的堆排序的堆就是指这种树状数据结构，除此之外还可以用来解决诸如 TopK，或者合并多个有序小文件之类的问题

优先级相同的元素我们还是遵循先进先出的原则，但一定会保证队列中优先级更高的元素先出队，即使它进队时间更晚

并不需要一直维护完全的顺序信息，只是需要能在每次出队时，找到优先级最高的元素即可

## 08｜外部排序：如何为TB级数据排序？

动态数组、双向链表、双端队列、栈、哈希表、红黑树、堆

常用数据结构的工业级实现

假设现在有 1TB 的任意文本，请问如何能将其中出现的单词按照字母序排列，得到一个新的文本？

内存可能没有这么大！

实际工作中，我们经常会遇到内存中放不下所有数据的排序场景。 早期可能因为内存的容量确实很小，而现在更多是因为我们需要存储的数据越来越大了，甚至不只是内存放不下，单机的硬盘可能也不够了，需要考虑分布式环境下的排序问题

当我们不能直接在内存中进行排序，而需要借助外存去处理极大量数据的排序时，就需要使用外部排序算法了

基于归并思想的外排过程

部分排序阶段

比较复杂的是归并阶段。因为内存不足以装下所有需要排序的元素，所以 O(nlogn) 的堆排和快排都已经没办法被应用在外排的场景中了，但基于分治思想的归并排序却依然可以很好地发挥作用。 而且相比很多其他排序方式比如选择排序、冒泡排序，归并排序 O(nlogn) 的复杂度已经是理论上相当好的复杂度了。当然在一些特定场景下我们也可以用一些线性排序算法比如桶排序来解决外部排序问题

我们在外存中需要读取多少次数据呢？从图中其实可以看出来，每一层我们读取外存的数据总量其实是一样的，本质上就是将所有的数据都遍历一遍。

对于 1TB 任意文本的排序问题，大致思路就是： 先用内排序算法，尽可能多的加载源文件，将其变成 n 个有序顺段。 在内存有限的前提下每 k 个文件为一组，每次流式地从各个文件中读取一个单词，借助败者树选出字典序最低的一个，输出到文件中，这样就可以将 k 个顺段合并到一个顺段中了；反复执行这样的操作，直至所有顺段被归并到同一个顺段。 这里稍微补充一下，看起来我们每次从文件中只读取了一个单词，但操作系统在读文件的时候是会按页为单位读取并缓存下来的，所以某一次磁盘访问之后的若干次访问，其实都会直接命中 cache，也就是说，并不是每次从败者树中取出元素时都会真的产生磁盘 IO，请不用担心。

归并阶段

得到若干个有序的文件段后，最后通过一些合并的方式，得到整体有序的文件

外部排序

## 09｜二分：如何高效查询Kafka中的消息？

如果每一次我们都猜测可能范围内的中间值，那么即使猜错了也能成倍的缩小范围，这样的策略其实就是二分查找算法。

二分查找相比于线性查找更快是有先决条件的，就是查找的范围内的元素一定是有序排列的。

以 Kafka 的索引查询为例，学习一下二分查找在工程实战中可以发挥的巨大威力

当然你可能会说，平时写业务代码的时候好像也没怎么写过二分查找。这其实也很正常，一是因为大部分时候，业务代码很少会在内存中存储大量的线性有序数据，在需要比较大量数据的检索时，我们往往会依赖底层的中间件；而数据量比较小时，线性查找和二分查找可能也差别不大了；另外我们也常常会用一些如红黑树这样的结构去存储有序集合，检索的时候也不会用到二分搜索这样在线性容器内的操作。 不过作为有追求的程序员，这种非常基础的算法思想我们还是很有必要掌握的，不止是能帮助你通过面试，更能帮助你更好地理解像 Kafka 这样的中间件的部分底层实现原理。

这里的“日志”不是说一般业务代码中用于 debug 的日志，而是一种存储的范式，这种范式只允许我们在文件尾部追加新数据，而不允许修改文件之前的任何内容。

为什么说是许多日志文件，而不是一个巨型的日志文件呢？这也是一个常用的计算机思想：分片。在这里，分片可以让我们更快速、更方便地删除部分无用文件，提高磁盘的利用率。

每条消息的消息体不同，每条消息所占用的磁盘大小都是不同的

每条消息的消息体不同，每条消息所占用的磁盘大小都是不同的

## 10｜搜索算法： 一起来写一个简单的爬虫？

实际上，许多博弈类游戏的过程，我们都可以用树来表示。根节点就是棋盘为空的状态，终点就是各个棋下完的状态，这样的树也被称为博弈树。

策梅洛定理

就是这么一个简单的井字棋小游戏，终局的数量非常多，达到了 255168 种。我们可以这样来简单地估计它，第一步有 9 种下法，第二步有 8 种下法，显然通过排列组合的知识，占满棋盘一共有 9！=362880 种下法，当然还需要去掉一些中间获胜不应该继续进行对弈的情况。

围棋盘有 19*19 个落子点，所以刚开始的每一步可能都有接近 361 个选择，那整体的情况可能接近 361！种。这是一个天文数字，在现在的计算机架构下，直接计算和存储这样的问题是不可能的。所以我们想要写出一个靠谱的围棋 AI，就需要采取一些新的策略，只选择部分分支进行遍历，从中找出一个比较好的方案。

AlphaGO 核心算法的名字“蒙特卡洛搜索树”中，就可以看出来，这本质上还是一个搜索的问题，只不过人类棋手和 AI 都采用了比较高明的搜索策略。

DFS 在前端开发中 DOM 树相关的操作里就非常常见，我们可以用它来实现对 DOM 树的遍历，从而对比两颗 DOM 树的差异，这就是 React 中虚拟 DOM 树算法的关键点之一。

BFS 和 DFS，作为两种最暴力、也相当常用的搜索策略，最大的特点就是无差别地去遍历搜索空间的每一种情况，因此但凡是可以抽象成图上的问题，基本上都可以考虑用 BFS、DFS 去做。只不过效率可能不是最优的，所以我们也常常称之为暴力搜索算法

在爬虫这样本来就需要无差别遍历全部空间的场景下可以说是非常合适的了

作为两个相当常用的暴力搜索算法，BFS 和 DFS 比较适合用来解决图规模不大，或者本身就需要无差别遍历搜索空间的每一种情况的问题；这两者的时间空间复杂度是相当的。

## 11｜字符串匹配：如何实现最快的grep工具

从一段文本中查找某个字符串存在的行

grep

GNU Grep 为什么这么快，主要有两点： 它避免了检查每一个 byte 对于被检查的 byte，只需要执行非常少的指令

## 12｜拓扑排序：Webpack是如何确定构建顺序的？

拓扑排序

如何在一堆有依赖关系的源文件中找到合适的加载或者编译的顺序

拓扑序是什么

优先选择没有入边也就是没有先修要求的

等修读完线性代数和高等数学之后你就会发现，诶这个时候数理方法和大学物理的先修课程已经全部被你解锁了

要修读的课程的先修课程一定在当前课程的前面。

你永远没有办法在一个有向有环的图中找到可以被拓扑排序的方案。

所有拓扑排序都是建立在有向无环图（DAG）上的

，DAG 这个词相信很多同学都很眼熟，在 Flink 和 Spark 这类可以用来做数据批计算或者流计算的框架中，就常常可以见到 DAG 这样的概念，用来做计算任务的调度。

Webpack 在打包 HTML 的时候是如何对 chunk 排序了吧，本质上就是一个对有向无环图输出节点“拓扑序”排列的问题。

平时用 brew 或者 apt-get 装包的时候计算机都会做哪些事情呢？一个包可能依赖了许许多多不同的包，计算机是从哪个包开始装起的呢？

## 13｜哈夫曼树：HTTP2.0是如何更快传输协议头的？

压缩多媒体数据时，我们允许一定程度的丢失。主要是因为对图像或者音频文件来说，数据一定程度上的丢失并不一定会很影响用户的主观感受。比如压缩图片时，有一种方式会把颜色的种类减少，让图片每个像素的编码位数降低，从而就实现了图片的压缩，但是从人的视觉上说影响可能并不是特别大。所以有损压缩的衡量指标就不止压缩比，还需要考虑人的主观感受了。 但是互联网大部分应用中所用的通信协议，都不应该关心业务数据本身，要做的只是保证数据可以按照一定的方式准确、无误，并且尽量高效地从发送端传输到接收端，有损压缩显然是不可接受的。比如最常用的 HTTP，就不会关心具体传输的内容是什么，自然不可能对数据做有损压缩。

h2load 是网上开源的一个对 HTTP/2.0 做 benchmark 的工具

哈夫曼思想非常简单，就是让出现概率更高的字符用更短的编码表示，出现概率低一些的字符则用更长的编码表示

我们日常在用的 ASCII 编码就是对字符串的一种编码，每个字符都被编码到 0-127 的范围里，这也是在绝大部分编程语言里，一个 char 类型的字符只占用一个字节的原因；当然，一个字节实际可以表示 0-255 种可能，ASCII 编码规范本身没有定义 128-255 的范围，所以各大厂商都可以有自己的扩展定义去表示更多的字符。

贪心算法，也就是在每一次决策时都采取在当前状态下最优的选择，从而得到整体最优解的算法。当然，也不是所有的场景都能使用贪心算法的，比如经典的背包问题，采用贪心算法虽然能得到局部最优解，但就不能得到全局最优解。而哈夫曼树则是一个贪心算法发挥作用的很好的例子。

## 14｜调度算法：操作系统中的进程是如何调度的？

进程调度算法，也就是 Process Scheduling Algorithms。

因为进程间切换的时间一般比较短，并不能达到人们能感知到的阈值，所以用户在使用计算机的时候就会觉得多个程序或者任务是同时，也就是并发，执行的

我们就看一种简化的模型来学习，把操作系统进程的状态分为 3 类：READY (就绪的) 、 RUNNING（运行的）、BLOCK（阻塞的）。

这是进程的第二个意义：可以提高程序的性能，让我们不必再空等 IO 的耗时，尽可能多地利用 CPU 的计算资源。

不同的调度算法，有不同的使用场景，很难说哪个算法一定比另一个更好，不同的算法只是在公平性、效率、吞吐量、等待时间等因素间做了不同的取舍，我们要根据实际的需要选择合适的调度算法。

React 的 fiber 机制也是源于操作系统的进程调度，它很好地解决了 React 网页应用可能因为一些 diff 等需要 cpu 密集计算的操作所带来的卡顿现象，让单线程的 JS 运行时有了“多线程”般的神奇能力。

## 15｜LRU：在虚拟内存中页面是如何置换的？

LRU 算法（Least recently used），也就是最近最少使用页面置换算法

其中 LRU 是实际应用最广的策略，因为它有着比较高的命中率并且实现非常简单，在虚拟内存系统中效果非常好。主要思想就是，当我们需要置换内存的时候，首先去替换最久没有被访问过的数据，这能很好利用数据的时间局部性，因为我们倾向认为最近被访问过的数据，在整个系统的生命周期里，有更大机会被访问到。

## 16｜日志型文件系统：写入文件的时候断电了会发生什么？

和一般的数据结构和算法主要考虑性能不同，文件系统还需要考虑一件非常重要的事情——数据的可持久化

写文件写到一半断电了，或者因为各种各样的原因系统崩溃了，系统重启之后文件是否还能被正常地读写呢？如果不能的话，我们应该怎么办呢？

这个问题，我们一般叫崩溃一致性问题（crash-consistent problem）。目前最流行的解决方案是 Linux 中的 Ext3 和 Ext4 文件系统所采用的日志方案，也就是 journaling，而 Ext3 和 Ext4 自然也就是所谓的日志型文件系统。

限于磁盘的物理结构，它读写的最小单位是扇区，大小是 512B，但是每次都只读一个扇区，不利于读写效率的提升；所以文件系统普遍会把多个扇区组成一个块，也就是 block。在 Ext4 中，逻辑块的大小是 4KB，包含 8 个扇区。

为了更灵活地存储文件、更高效地利用磁盘空间、更快速地访问到每个文件的数据存储在哪些块上，Linux 的做法是把文件分成几块区域：至少包括超级块、索引节点区、数据块区。 超级块，是文件系统中的第一个块，用来存放文件系统本身的信息，比如可以用于记录每块区域的大小； 索引节点区，每个文件对应索引节点区中的一个块，我们称为索引节点，也就是 Inode，存放每个文件中所用到的数据块的地址，Inode 也是元数据主要存储的地方； 数据块区，也就是 Data Blocks，这里是真实数据存放的区域，一个文件的 inode 可能存有多个指向数据块的指针。 另外，为了标记哪些 Inodes 和 Data Blocks 可以被使用，操作系统还建立了两块存放 Bitmap 的区域。

现在，我们搞清楚了崩溃一致性问题的本质，自然就要尝试解决它。历史上比较流行的解决方案有两种：一种是早期操作系统普遍采用的 FSCK 机制（file system check），另一种就是我们今天主要学习的日志机制（journaling file system）。

日志型文件系统这个方案，其实是从 DBMS 也就是数据库系统中借鉴而来的。

journaling file system 的核心思想是鼎鼎大名的预写日志 WAL 也就是 write-ahead logging

我们每次进行一次对文件的写操作，除了会先在预写日志中，记录对 Inodes 的修改记录、对 Bitmaps 的修改记录，以及对具体数据块的修改记录之外，还会同时在这几条记录的前后，分别引入一个事务开始记录和一个事务结束记录。

第一个写入的记录是 TxB，也就是 Transaction Begin 记录，最后一个写入的记录就是 TxE 也就是 Transaction End 记录，在 TxE 记录完成后，就意味着整个写文件的操作全过程都被记录在案了，我们把这个步骤叫做 Journal Write。

如果崩溃出现在 journal write 步骤中 假设崩溃是出现在 TxE 块完成写操作之前，那其实对系统也没有任何影响。因为相当于事务没有被成功提交，而我们写的是日志，对文件本身也没有任何实际影响。 当系统断电又恢复之后，只要发现某个事务 ID 没有对应的 TxE 块，说明这个事务没有提交成功，不可能进入 checkpointing 阶段，丢弃它们对文件系统没有任何不良影响，只是相当于上次写文件的操作失败了而已。

如果崩溃刚好发生在 journal write 结束之后 不管是刚刚写完 TxE，还是已经进入了 checkpointing 的某一步，我们的处理也都是一样的。既然事务已经被提交，系统断电恢复之后，我们也不用关心之前到底 checkpointing 执行到了哪一步，比如是已经更新了 inodes？还是 bitmaps？都没有任何影响，直接按照日志重做一遍就可以，最坏的下场也不过就是重新执行了一遍执行过的操作。 顾名思义，这种重做一遍的日志我们也把它称为 redo logging，它也是一种最基本、最常见的日志记录方式。不只在文件系统中，在数据库等场景下也使用非常广泛。

如果真的发生错误的时候，没有关系，我们回去查阅一下日志，按照日志记录的操作从头到尾重新做一遍就可以了。

## 17｜选路算法：Dijkstra是如何解决最短路问题的？

Dijkstra 算法是一个非常经典的求解单源最短路 (Single Source Shortest Path) 问题的算法，但它有一个巨大的限制：只能用于没有权重为负的边的图。

## 20｜滑动窗口：TCP是如何进行流量控制和拥塞控制的？

TCP 就是通过滑动窗口、拥塞窗口这两个简单的窗口实现了流量控制和拥塞控制。

## 21｜分而治之：MapReduce如何解决大规模分布式计算问题

想要任务在 MapReduce 机器上顺利执行，大体上来说就是要做到把数据分区，交给不同的机器执行，在要汇总的时候也需要有办法进行数据的汇总，并且要有一定应对故障的能力。

## 22｜PageRank：谷歌是如何计算网页排名的

有相当多的学者在用图的方法研究学术网络中的问题，如果你把论文看成图，那么论文之间的引用关系就是一条条有向边，入边越多的节点，影响力一般来说也越高。 网页和学术论文其实在有些方面是很像的。如果把网页看成图上的节点，由于网页之间有一些超链接指向，谷歌所能爬到的所有网页就会构成一张类似于学术网络的图。 PageRank 对网页的排名，本质上也是这样一种基于引用情况和影响力的排名。背后的逻辑很简单，被更多超链接指向的网页，可以推断它往往会有更好的质量

## 23｜Raft：分布式系统间如何达成共识？

分布式系统由于大量使用廉价的商用机器，节点故障是不可避免的。

一种最暴力的做法可能是：定义一个主节点，每一次写请求都请求到主节点，等主节点一致性模块向集群中的每个节点都成功写入了同样一份数据，再返回给客户端成功的消息，进行消息的 commit。只要有一个失败，就不进行消息的 commit。 但是我们看这个方案，显然不是很高效。无论是存在慢节点，会导致整体响应被拖的很慢，还是一台节点挂了，会导致整个集群不可用，都是不可接受的。

那我们分析一下在实际系统中，一致性算法通常会存在哪些问题： 在分区、网络延迟、乱序等情况下都需要保证安全性，也就是说需要数据一旦返回，一定是正确的。 可用性问题。部分节点故障，但在集群中大部分节点可运行且能互相通信的情况下，要保证整个系统是可以工作的。 不依赖时钟保证一致性。因为物理时钟在分布式系统中是不可信的，不同节点间的时间并不同步的，而且随时可能因为时钟同步而导致时钟回跳等等。 慢节点，要求不能影响系统整体性能。

Raft 和 Paxos 都是只要有超过一半的服务器可以运行并互相可通信，就可以保证整个系统可用。

## 24｜UUID：如何高效生成全局的唯一ID？

全局唯一 ID 的两个核心需求就是： 全局唯一性 粗略有序性

时钟为什么会回拨呢？ 如果你了解计算机如何计时的话就知道，计算机底层的计时主要依靠石英钟，它本身是有一定误差，所以计算机会定期地通过 NTP 服务，来同步更加接近真实时间的时间（仍然有一定的误差），这个时候就可能会产生时钟的一些跳跃

## 25｜一致性哈希：如何在集群上合理分配流量？

什么样的请求或者服务是带有状态的呢？ 比如一个分布式 KV 缓存系统，为了提高整个系统的容量，我们往往会把数据水平切分到不同的节点来存储，当然为了提供更好的系统可用性，在部分不同节点上存储时，我们会让数据产生一定的冗余。对于这样的系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的，不是说任意访问一个节点都可以得到缓存结果的。这样的服务，我们就可以认为是有状态的。

假设一个集群有 20 个可以对外服务的节点，有很多的客户端同时在请求这些服务，我们希望每次从同一个客户端访问的请求，下次再请求集群的时候，也能打到和这次一样的节点上。这不就类似散列表的需求嘛：对任意 key 映射到一段连续数组空间，且同一个 key 每次映射都会映射到数组的同一个位置。

一致性哈希

## 26｜B+ Tree：PostgreSQL 的索引是如何建立的？

有没有什么办法利用磁盘读写的特性，既可以保持树状结构的灵活性，又同时降低查询的 IO 次数呢？这就是 B+ 树的用武之地了，核心就是通过引入更多的分叉，在节点同样数量级的范围内，显著地降低树状索引的层数。

B- 树 B+ 树 B+ 树是传统关系型数据库索引的标配，在 MySQL、PostgreSQL 等主流 DBMS 中，B+ 树都是索引的底层实现。 B+ 树是由 B- 树演化而来，这里的 B 一般被解读为 balance，也就是平衡树，和之前介绍的 2-3 树差不多，B- 树、B+ 树每个节点也包含多个键和多条链。

## 28｜MVCC：如何突破数据库并发读写性能瓶颈？

事务就是指一系列操作，这些操作要么全部执行成功并提交，要么有一个失败然后全部回滚像什么都没发生一样，绝对不会存在中间有一部分操作得以执行，一部分没有执行。

脏读问题，也就是在事务开始时，读到了尚未提交的其他并发事务对数据的修改值。 为什么我们称为脏值，主要因为这个值是可能会回滚的，比如如果 B 事务失败了，100 这个值并没有真的被写入成功，会被撤销掉，但是我们竟然在 A 事务里看到了，这种情况我们称为脏，很好理解。 除脏读，数据库中常见的“有问题的”查询结果还有 2 种情况：不可重复读、幻读。 不可重复读，是指在事务的过程中对同一个数据，读到了两次不同的值，即使别的事务在当前事务的生命周期里对该数据做了修改。 幻读，在事务的过程里读取符合某个查询条件的数据，第一次没有读到某个记录，而第二次读竟然读到了这个记录，像发生了幻觉一样，这也是它被称为幻读的原因。 因为存在这三种问题，脏读、不可重复读、幻读，业务很可能会产生错误，所以我们就需要根据不同的业务场景，提供不同的事务隔离等级，你可以理解成某个事务对其他事务修改数据结果的可见性情况。

利用 MVCC 实现可重复读 MVCC，全称 Multi-Version Concurrency Control

## 29｜位图：如何用更少空间对大量数据进行去重和排序？

事实上，40 亿级的数据范围，在 1GB 的内存下，我们是有办法直接在内存中处理去重的，这就是我们今天要学习的 Bitmap，它非常有用，在计算机的世界里无处不在，从文件系统、数据库，还有 Redis 中都有广泛应用。

在 QQ 号的场景下，要表示 40 亿的元素，采用 Bitmap，最少只需要 40 亿个 bits，所占据的空间大约是 500M 左右，这样，我们就大大压缩了内存的使用空间，在 1GB 之内就可以完成去重的工作。

这里插句题外话，不知道你有没有想过为什么 bool 类型，在大部分语言中，都需要一个 byte 去存储呢？bool 本身语意上就只是二值，我们不应该用一个 bit 来实现吗，这样不是效率高得多？ 这个问题，需要我们有比较好的计算机组成原理相关的知识了。本质原因是在大部分的计算机架构中，最小的内存操作单元就是一个 byte，直接采用一个 byte 作为 bool 类型的存储，在一次读内存的操作内即可完成，如果存储为一个 bit，我们还需要像 Bitmap 那样，从若干位中通过位运算进行一次提取操作，反而更慢。

## 30｜布隆过滤器：如何解决Redis缓存穿透问题？

布隆过滤器起到的是过滤的作用，在缓存穿透的场景下，过滤掉肯定不在系统中 key 的相关请求。所以，布隆过滤器，核心就是要维护一个数据结构，我们通过它来快速判断某个 key 是否存在于某个集合中。

Google 提供的经典 Java 工具库 Guava 中，就有一个对 bloom filter 的实现，它提供了很好的泛化能力

Guava 库的代码质量很高，也不是特别难懂，如果你是 Java 爱好者，不妨用这个库开始你的源码学习之旅。

## 32｜时间轮：Kafka是如何实现定时任务的？

Kafka 就是一个非常好用的选择，作为一款高性能的消息队列，Kafka 天然支持了延时消息的能力，可以帮助我们处理所有的延时场景下的问题。

DelayedQueue，作为 JDK 原生支持的数据结构，能非常方便地帮助我们支持单机、数据规模不大的延时队列的场景。

## 特别策划｜面试：BAT面试三关准备方法大揭秘

CMU 15445，讲数据库非常好的一门课，里面讲了很多经典的 paper。帮助你非常系统地梳理数据库发展的历史，而且内容很新。 CMU 15213，可以打好计算机体系结构和操作系统的知识基础。CSAPP 是这门课的指定教材。 MIT 6.824，课程会带着你一起阅读许多经典的分布式领域的论文，了解大规模互联网应用会遇到哪些问题。 DDIA，被国外很多同学称为系统设计的圣经，同样是能带你系统了解许多基础数据系统设计精髓的经典书籍。 SICP，能很好的帮助你了解编程语言底层原理。

